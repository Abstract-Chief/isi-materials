# Конспект по Машинному Обучению и Алгоритмам

## Введение
Данный конспект охватывает ключевые темы, связанные с прохождением кодовых заданий, изучением алгоритмов, обработкой данных, моделированием, кластеризацией и методами оптимизации признаков. В финале также разобраны алгоритмы решения задач типа Number Puzzle и Sudoku.

---

# Основные темы

## 1. Цвик 1 — Базовая ML-практика

### 1.1 Подготовка данных
- Использование линейного ядра в `SVC(kernel='linear')` подходит для данных без больших отклонений.
- Разделение на обучающую и тестовую выборки необходимо для корректного тестирования модели.

### 1.2 Общий алгоритм обучения моделей
1. Получить датасет  
2. Разделить данные:  
   `x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)`
3. Инициализировать модель  
4. Предсказать значения  
5. Оценить точность: `accuracy_score(y_test, y_pred)`

### 1.3 Decision Tree
Параметры:
- **max_depth** — ограничивает глубину дерева (меньше → проще модель)
- **min_samples_split** — минимальное число элементов для разбиения (больше → шире и стабильнее дерево)

---

## 2. Цвик 2 — Titanic Dataset

### 2.1 Очистка данных
- Удаление ненужных колонок
- Заполнение пропусков средним значением
- Кодирование категориальных значений (`LabelEncoder`)
- One-hot кодирование класса (class 1 / class 2 / class 3)

### 2.2 Финальный шаг
- Обучение DecisionTreeClassifier
- Предсказание вероятности выживания

---

## 3. Кластеризация

### 3.1 K-Means
- Делит точки на **K кластеров**
- Distortion — сумма квадратов расстояний до центров кластеров

### 3.2 Elbow Method
- Позволяет выбрать оптимальное K
- Малое K — слишком большие и размытые группы  
- Большое K — переусложнение модели

---

## 4. Кросс-валидация (K-fold)

### Зачем нужна
Проверяет, как хорошо модель обобщает данные.

### Как работает
- Данные делятся на K частей
- На каждом шаге одна часть — TEST, остальные — TRAIN
- Итог — стабильная оценка точности

---

## 5. Выборка признаков

### 5.1 VarianceThreshold
Удаляет колонки с малой дисперсией → неинформативные признаки.

### 5.2 SelectFromModel
Использует модель (например, RandomForest) для определения важных признаков.

### 5.3 RFECV
Процесс:
1. Обучить модель
2. Удалить наименее важный признак
3. Повторять до 1 признака
4. На каждом шаге проводить кросс-валидацию  
→ Находит оптимальное число признаков

---

## 6. Цвик 5 — Регрессия
- `make_regression()` генерирует искусственный датасет  
- Регрессия предсказывает **числовое** значение  
  (например, цена дома, вес, рост)

---

# Алгоритмы

## Number Puzzle

### BFS
Поиск в ширину:
- Проходит состояния слоями: 1 шаг → 2 шага → 3 шага.

**Псевдокод:**
```
queue = [start]
while queue:
    state = queue.pop(0)
    if goal(state):
        return state
    queue.extend(neighbors(state))
```

### DFS
Идет в глубину до упора или лимита.

### Greedy Search
Выбирает следующий шаг по минимальной эвристике (оценке близости).

### A*
Улучшение Greedy:
- Учитывает расстояние от начального состояния:  
  `f(n) = g(n) + h(n)`

---

## Sudoku

### Domain
Набор возможных значений клетки, зависящий от строки, столбца и квадрата.

### FC — Forward Checking
- После присвоения числа исключает его из доменов связанных клеток.
- Если домен пуст — откат.

### MRV
Minimum Remaining Values  
Выбор клетки с минимальным числом доступных значений.

### LCV
Least Constraining Value  
Выбирает значение, которое меньше всего ограничивает соседей.

---

# Код

```python
svc = SVC(kernel='linear')
X_train, X_test, y_train, y_test = train_test_split(
    faces.data, faces.target, test_size=0.25, random_state=0
)
```

```python
titanic_data = pd.read_csv('data/titanic.txt')
titanic_y = np.array(titanic_data.survived)
titanic_reduced = titanic_data.drop(columns=[...])
```

```python
clf = tree.DecisionTreeClassifier(
    criterion='entropy', max_depth=6, min_samples_leaf=10
)
```

```python
selector = VarianceThreshold(threshold=0.01)
new_selection = selector.fit_transform(data)
```

---

# Выводы

- Для качественного обучения моделей важно корректно подготавливать данные.
- Кросс-валидация значительно повышает устойчивость оценки.
- Кластеризация требует подбора оптимального K.
- Выборка признаков уменьшает шум и увеличивает качество модели.
- Алгоритмы поиска (BFS, DFS, Greedy, A*) имеют разные стратегии и применяются под разные задачи.
- Для Sudoku эффективны MRV, LCV и Forward Checking.

